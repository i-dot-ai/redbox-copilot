{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from redbox.graph.root import get_redbox_graph, run_redbox\n",
    "from redbox.graph.chat import get_chat_with_docs_graph\n",
    "from redbox.chains import components\n",
    "from redbox.models.settings import Settings, ElasticLocalSettings, AISettings\n",
    "from redbox.models.chain import ChainInput, ChainState\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv, dotenv_values\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "import tiktoken\n",
    "\n",
    "_ = load_dotenv(Path.cwd().parent / \".env\")\n",
    "\n",
    "ENV = Settings(\n",
    "    minio_host=\"localhost\", \n",
    "    object_store=\"minio\", \n",
    "    azure_openai_model=\"gpt-4o\",\n",
    "    elastic=ElasticLocalSettings(host=\"localhost\"),\n",
    ")\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    api_key=ENV.azure_openai_api_key,\n",
    "    azure_endpoint=ENV.azure_openai_endpoint,\n",
    "    model=ENV.azure_openai_model,\n",
    ")\n",
    "\n",
    "AI_CONFIG = {\"configurable\": ENV.ai.dict()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import UUID\n",
    "from langchain_core.documents import Document\n",
    "from redbox.models.chat import ChatRoute\n",
    "from typing import Annotated, TypedDict\n",
    "\n",
    "type DocumentState = dict[UUID, dict[UUID, Document]]\n",
    "\n",
    "def document_reducer(left: DocumentState, right: DocumentState) -> DocumentState:\n",
    "    \"\"\"Merges two document states based on the following rules.\n",
    "    \n",
    "    * Groups are matched by the group key.\n",
    "    * Documents are matched by the group key and document key.\n",
    "\n",
    "    Then:\n",
    "    \n",
    "    * If key(s) are matched, the group or Document is replaced\n",
    "    * If key(s) are matched and the key is None, the key is cleared\n",
    "    * If key(s) aren't matched, group or Document is added\n",
    "    \"\"\"\n",
    "    # If state is empty, return right\n",
    "    if left is None:\n",
    "        return right\n",
    "    \n",
    "    # Copy left\n",
    "    reduced = {k: v.copy() for k, v in left.items()}\n",
    "    \n",
    "    # Update with right\n",
    "    for group_key, group in right.items():\n",
    "        # If group is None, remove from output if a group key is matched\n",
    "        if group is None:\n",
    "            reduced.pop(group_key, None)\n",
    "            continue\n",
    "        \n",
    "        # If group key isn't matched, add it\n",
    "        if group_key not in reduced:\n",
    "            reduced[group_key] = group\n",
    "\n",
    "        \n",
    "        for document_key, document in group.items():\n",
    "            if document is None:\n",
    "                # If Document is None, remove from output if a group and document key is matched\n",
    "                reduced[group_key].pop(document_key, None)\n",
    "            else:\n",
    "                # Otherwise, update or add the value\n",
    "                reduced[group_key][document_key] = document\n",
    "\n",
    "        # Remove group_key from output if it becomes empty after updates\n",
    "        if not reduced[group_key]:\n",
    "            del reduced[group_key]\n",
    "\n",
    "    return reduced\n",
    "\n",
    "class State(TypedDict):\n",
    "    request: ChainInput\n",
    "    text: str | None\n",
    "    documents: Annotated[DocumentState, document_reducer] | None\n",
    "    route: ChatRoute | None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = {\n",
    "    UUID(\"00000000-0000-0000-0000-000000000001\"): {\n",
    "        UUID(\"10000000-0000-0000-0000-000000000000\"): Document(page_content=\"a\"),\n",
    "        UUID(\"20000000-0000-0000-0000-000000000000\"): Document(page_content=\"b\")\n",
    "    },\n",
    "    UUID(\"00000000-0000-0000-0000-000000000002\"): {\n",
    "        UUID(\"30000000-0000-0000-0000-000000000000\"): Document(page_content=\"c\"),\n",
    "        UUID(\"40000000-0000-0000-0000-000000000000\"): Document(page_content=\"d\")\n",
    "    }\n",
    "}\n",
    "\n",
    "y = {\n",
    "    UUID(\"00000000-0000-0000-0000-000000000001\"): {\n",
    "        UUID(\"10000000-0000-0000-0000-000000000000\"): Document(page_content=\"z\"),\n",
    "        UUID(\"20000000-0000-0000-0000-000000000000\"): None,\n",
    "        UUID(\"30000000-0000-0000-0000-000000000000\"): Document(page_content=\"c\")\n",
    "    },\n",
    "    UUID(\"00000000-0000-0000-0000-000000000002\"): None\n",
    "}\n",
    "\n",
    "z = {\n",
    "    UUID(\"00000000-0000-0000-0000-000000000001\"): {\n",
    "        UUID(\"10000000-0000-0000-0000-000000000000\"): Document(page_content=\"z\"),\n",
    "        UUID(\"30000000-0000-0000-0000-000000000000\"): Document(page_content=\"c\")\n",
    "    }\n",
    "}\n",
    "\n",
    "a = document_reducer(x, y)\n",
    "\n",
    "a == z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "import re\n",
    "\n",
    "def calculate_token_budget(state: State, config: AISettings) -> int:\n",
    "    tokeniser = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "    len_question = len(tokeniser.encode(state[\"request\"].question))\n",
    "    max_system_or_question_prompt = max(\n",
    "        [\n",
    "            len(tokeniser.encode(v))\n",
    "            for k, v in config[\"configurable\"].items() \n",
    "            if isinstance(v, str)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    len_prompts = max_system_or_question_prompt * 2\n",
    "    # config.llm_max_tokens is 1024 -- move max tokens to AISettings\n",
    "    len_max_output = 1_024\n",
    "    \n",
    "    return config[\"configurable\"][\"context_window_size\"] - len_max_output - len_prompts - len_question\n",
    "\n",
    "def conditional_doceuments_bigger_than_context(state: State, config: AISettings) -> bool:\n",
    "    token_budget = calculate_token_budget(state=state, config=config)\n",
    "\n",
    "    if sum(d.metadata[\"token_count\"] for d in state[\"documents\"]) > token_budget:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def conditional_keyword_detection(state: State, config: AISettings) -> ChatRoute | None:\n",
    "    re_keyword_pattern = re.compile(r\"@(\\w+)\")\n",
    "\n",
    "    route_match = re_keyword_pattern.search(state[\"request\"].question)\n",
    "    route_name = route_match.group()[1:] if route_match else None\n",
    "    \n",
    "    try:\n",
    "        return ChatRoute[route_name]\n",
    "    except KeyError:\n",
    "        return None\n",
    "\n",
    "def conditional_documents_selected(state: State, config: AISettings) -> bool:\n",
    "    return len(state[\"request\"].file_uuids) > 0\n",
    "\n",
    "def conditional_multiple_docs_in_group(state: State, config: AISettings) -> bool:\n",
    "    for group in state[\"documents\"]:\n",
    "        if len(state[\"documents\"][group]) > 0:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.constants import Send\n",
    "from typing import Callable\n",
    "\n",
    "def make_document_group_send(target: str) -> Callable[[State, AISettings], list[Send]]:\n",
    "    def _group_send(state: State, config: AISettings) -> list[Send]:\n",
    "        group_send_states: list[State] = [\n",
    "            State(\n",
    "                request=state[\"request\"],\n",
    "                text=state[\"text\"],\n",
    "                documents={group_key: state[\"documents\"][group_key]},\n",
    "                route=state[\"route\"]\n",
    "            )\n",
    "            for group_key in state[\"documents\"]\n",
    "        ]\n",
    "        return [Send(node=target, arg=state) for state in group_send_states]\n",
    "    return _group_send\n",
    "\n",
    "def make_document_chunk_send(target: str) -> Callable[[State, AISettings], list[Send]]:\n",
    "    def _chunk_send(state: State, config: AISettings) -> list[Send]:\n",
    "        chunk_send_states: list[State] = [\n",
    "            State(\n",
    "                request=state[\"request\"],\n",
    "                text=state[\"text\"],\n",
    "                documents={group_key: {document_key: state[\"documents\"][group_key][document_key]}},\n",
    "                route=state[\"route\"]\n",
    "            )\n",
    "            for group_key in state[\"documents\"]\n",
    "            for document_key in state[\"documents\"][group_key]\n",
    "        ]\n",
    "        return [Send(node=target, arg=state) for state in chunk_send_states]\n",
    "    return _chunk_send\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_document_state(documents: dict[UUID, dict[UUID, Document]]) -> list[Document]:\n",
    "    return [\n",
    "        document\n",
    "        for group in documents.values()\n",
    "        for document in group.values()\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"Arrr matey! I be Cap'n Quill, master of the seven seas and keeper of hidden treasures. What be yer business aboard me vessel?\"}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.language_models.chat_models import BaseChatModel\n",
    "from langchain_core.output_parsers.string import StrOutputParser\n",
    "from langchain_core.retrievers import BaseRetriever\n",
    "\n",
    "from redbox.api.runnables import make_chat_prompt_from_messages_runnable\n",
    "\n",
    "from typing import Any\n",
    "\n",
    "def make_chat_pattern(\n",
    "    system_prompt: str,\n",
    "    question_prompt: str,\n",
    "    llm: BaseChatModel,\n",
    ") -> Callable[[State, AISettings], dict[str, Any]]:\n",
    "    \"\"\"Returns a function that uses state[\"request\"] to set state[\"text\"].\"\"\"\n",
    "    def _chat(state: State, config: AISettings) -> dict[str, Any]:\n",
    "        chat_chain = (\n",
    "            make_chat_prompt_from_messages_runnable(\n",
    "                system_prompt=system_prompt,\n",
    "                question_prompt=question_prompt,\n",
    "                input_token_budget=config[\"configurable\"][\"context_window_size\"] - 1_024,\n",
    "                tokeniser=tiktoken.get_encoding(\"cl100k_base\"),\n",
    "            )\n",
    "            | llm\n",
    "            | StrOutputParser()\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"text\": chat_chain.invoke(state[\"request\"]),\n",
    "        }\n",
    "\n",
    "    return _chat\n",
    "\n",
    "chat_state = State(\n",
    "    request=ChainInput(\n",
    "        question=\"Who are you?\",\n",
    "        file_uuids=[],\n",
    "        user_uuid=\"a16b2762-fc18-4595-bafa-3d70f1e85087\",\n",
    "        chat_history=[],\n",
    "    ).dict(),\n",
    "    text=None,\n",
    "    documents=None,\n",
    "    route=None\n",
    ")\n",
    "\n",
    "chat_node = make_chat_pattern(\n",
    "    system_prompt=\"You're a pirate.\", \n",
    "    question_prompt=\"{question}\\n\\n Response: \",\n",
    "    llm=llm\n",
    ")\n",
    "\n",
    "chat_node(chat_state, AI_CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Who are you?'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_passthrough_pattern() -> Callable[[State, AISettings], dict[str, Any]]:\n",
    "    \"\"\"Returns a function that uses state[\"request\"] to set state[\"text\"].\"\"\"\n",
    "    def _passthrough(state: State, config: AISettings) -> dict[str, Any]:\n",
    "        return {\n",
    "            \"text\": state[\"request\"][\"question\"],\n",
    "        }\n",
    "    \n",
    "    return _passthrough\n",
    "    \n",
    "passthrough_state = State(\n",
    "    request=ChainInput(\n",
    "        question=\"Who are you?\",\n",
    "        file_uuids=[],\n",
    "        user_uuid=\"a16b2762-fc18-4595-bafa-3d70f1e85087\",\n",
    "        chat_history=[],\n",
    "    ).dict(),\n",
    "    text=None,\n",
    "    documents=None,\n",
    "    route=None\n",
    ")\n",
    "\n",
    "passthrough_node = make_passthrough_pattern()\n",
    "\n",
    "passthrough_node(passthrough_state, AI_CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'I am the walrus'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_canned_pattern(canned: str) -> Callable[[State, AISettings], dict[str, Any]]:\n",
    "    \"\"\"Returns a function that uses state[\"request\"] to set state[\"text\"].\"\"\"\n",
    "    def _canned(state: State, config: AISettings) -> dict[str, Any]:\n",
    "        return {\n",
    "            \"text\": canned,\n",
    "        }\n",
    "    \n",
    "    return _canned\n",
    "    \n",
    "canned_state = State(\n",
    "    request=ChainInput(\n",
    "        question=\"Who are you?\",\n",
    "        file_uuids=[],\n",
    "        user_uuid=\"a16b2762-fc18-4595-bafa-3d70f1e85087\",\n",
    "        chat_history=[],\n",
    "    ).dict(),\n",
    "    text=None,\n",
    "    documents=None,\n",
    "    route=None\n",
    ")\n",
    "\n",
    "canned_node = make_canned_pattern(canned=\"I am the walrus\")\n",
    "\n",
    "canned_node(canned_state, AI_CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'The animals named in the documents are:\\n\\n1. Dog\\n2. Cat\\n3. Swift\\n4. Shrike'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough \n",
    "\n",
    "from redbox.api.format import format_documents\n",
    "\n",
    "from operator import itemgetter\n",
    "\n",
    "def make_stuff_pattern(\n",
    "    system_prompt: str,\n",
    "    question_prompt: str,\n",
    "    llm: BaseChatModel,\n",
    ") -> Callable[[State, AISettings], dict[str, Any]]:\n",
    "    \"\"\"Returns a function that uses state[\"request\"] and state[\"documents\"] to set state[\"text\"].\"\"\"\n",
    "    def _stuff(state: State, config: AISettings) -> dict[str, Any]:\n",
    "        stuff_chain = (\n",
    "            RunnablePassthrough.assign(\n",
    "                documents=(\n",
    "                    RunnablePassthrough() \n",
    "                    | itemgetter(\"documents\") \n",
    "                    | flatten_document_state \n",
    "                    | format_documents\n",
    "                )\n",
    "            ) \n",
    "            | make_chat_prompt_from_messages_runnable(\n",
    "                system_prompt=system_prompt,\n",
    "                question_prompt=question_prompt,\n",
    "                input_token_budget=config[\"configurable\"][\"context_window_size\"] - 1_024,\n",
    "                tokeniser=tiktoken.get_encoding(\"cl100k_base\"),\n",
    "            )\n",
    "            | llm\n",
    "            | StrOutputParser()\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"text\": stuff_chain.invoke({\n",
    "                **state[\"request\"],\n",
    "                \"documents\": state[\"documents\"]\n",
    "            })\n",
    "        }\n",
    "\n",
    "    return _stuff\n",
    "\n",
    "stuff_state = State(\n",
    "    request=ChainInput(\n",
    "        question=\"What animals are named in these documents?\",\n",
    "        file_uuids=[\"71b76e2a-9c2f-4340-ba94-cc09c7de74ff\"],\n",
    "        user_uuid=\"a16b2762-fc18-4595-bafa-3d70f1e85087\",\n",
    "        chat_history=[],\n",
    "    ).dict(),\n",
    "    text=None,\n",
    "    documents={\n",
    "        UUID(\"00000000-0000-0000-0000-000000000001\"): {\n",
    "            UUID(\"10000000-0000-0000-0000-000000000000\"): Document(\n",
    "                page_content=\"A dog is a type of mammal.\",\n",
    "                metadata={\n",
    "                    \"uuid\": UUID(\"10000000-0000-0000-0000-000000000000\"),\n",
    "                    \"parent_file_uuid\": UUID(\"00000000-0000-0000-0000-000000000001\"),\n",
    "                    \"token_count\": 6,\n",
    "                }\n",
    "            ),\n",
    "            UUID(\"20000000-0000-0000-0000-000000000000\"): Document(\n",
    "                page_content=\"A cat is a type of mammal.\",\n",
    "                metadata={\n",
    "                    \"uuid\": UUID(\"20000000-0000-0000-0000-000000000000\"),\n",
    "                    \"parent_file_uuid\": UUID(\"00000000-0000-0000-0000-000000000001\"),\n",
    "                    \"token_count\": 6,\n",
    "                }\n",
    "            )\n",
    "        },\n",
    "        UUID(\"00000000-0000-0000-0000-000000000002\"): {\n",
    "            UUID(\"30000000-0000-0000-0000-000000000000\"): Document(\n",
    "                page_content=\"A swift is a type of bird.\",\n",
    "                metadata={\n",
    "                    \"uuid\": UUID(\"30000000-0000-0000-0000-000000000000\"),\n",
    "                    \"parent_file_uuid\": UUID(\"00000000-0000-0000-0000-000000000002\"),\n",
    "                    \"token_count\": 6,\n",
    "                }\n",
    "            ),\n",
    "            UUID(\"40000000-0000-0000-0000-000000000000\"): Document(\n",
    "                page_content=\"A shrike is a type of bird.\",\n",
    "                metadata={\n",
    "                    \"uuid\": UUID(\"40000000-0000-0000-0000-000000000000\"),\n",
    "                    \"parent_file_uuid\": UUID(\"00000000-0000-0000-0000-000000000002\"),\n",
    "                    \"token_count\": 6,\n",
    "                }\n",
    "            )\n",
    "        }\n",
    "    },\n",
    "    route=None\n",
    ")\n",
    "\n",
    "stuff_node = make_stuff_pattern(\n",
    "    system_prompt=\"Summarise these documents.\", \n",
    "    question_prompt=\"Question: {question}. \\n\\n Documents: \\n\\n {documents} \\n\\n Answer:\",\n",
    "    llm=llm\n",
    ")\n",
    "\n",
    "stuff_node(stuff_state, AI_CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'documents': {UUID('00000000-0000-0000-0000-000000000001'): {UUID('10000000-0000-0000-0000-000000000000'): Document(metadata={'uuid': UUID('10000000-0000-0000-0000-000000000000'), 'parent_file_uuid': UUID('00000000-0000-0000-0000-000000000001'), 'token_count': 24, 'page_number': None, 'languages': None, 'link_texts': None, 'link_urls': None, 'links': None}, page_content='The animals named in the documents are:\\n\\n1. Dog\\n2. Cat\\n3. Swift\\n4. Shrike'),\n",
       "   UUID('20000000-0000-0000-0000-000000000000'): None},\n",
       "  UUID('00000000-0000-0000-0000-000000000002'): {UUID('30000000-0000-0000-0000-000000000000'): None,\n",
       "   UUID('40000000-0000-0000-0000-000000000000'): None}}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from redbox.transform import combine_documents\n",
    "\n",
    "from functools import reduce\n",
    "from uuid import uuid4\n",
    "\n",
    "def make_merge_pattern(\n",
    "    system_prompt: str,\n",
    "    question_prompt: str,\n",
    "    llm: BaseChatModel,\n",
    ") -> Callable[[State, AISettings], dict[str, Any]]:\n",
    "    \"\"\"Returns a function that uses state[\"request\"] and state[\"documents\"] to return one item in state[\"documents\"].\n",
    "    \n",
    "    When combined with chunk send, will replace each Document with what's returned from the LLM.\n",
    "\n",
    "    When combined with group end, with combine all Documents and use the metadata of the first.\n",
    "\n",
    "    When used without a send, the first Document receieved defines the metadata.\n",
    "    \"\"\"\n",
    "    def _merge(state: State, config: AISettings) -> dict[str, Any]:\n",
    "        tokeniser = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "        flattened_documents = flatten_document_state(state[\"documents\"])\n",
    "        \n",
    "        merged_document = reduce(lambda l, r: combine_documents(l, r), flattened_documents)\n",
    "        \n",
    "        stuff_chain = (\n",
    "            RunnablePassthrough.assign(\n",
    "                documents=(\n",
    "                    RunnablePassthrough() \n",
    "                    | itemgetter(\"documents\") \n",
    "                    | flatten_document_state \n",
    "                    | format_documents\n",
    "                )\n",
    "            ) \n",
    "            | make_chat_prompt_from_messages_runnable(\n",
    "                system_prompt=system_prompt,\n",
    "                question_prompt=question_prompt,\n",
    "                input_token_budget=config[\"configurable\"][\"context_window_size\"] - 1_024,\n",
    "                tokeniser=tokeniser,\n",
    "            )\n",
    "            | llm\n",
    "            | StrOutputParser()\n",
    "        )\n",
    "        \n",
    "        merged_document.page_content = stuff_chain.invoke({\n",
    "            **state[\"request\"],\n",
    "            \"documents\": state[\"documents\"]\n",
    "        })\n",
    "        merged_document.metadata[\"token_count\"] = len(\n",
    "            tokeniser.encode(merged_document.page_content)\n",
    "        )\n",
    "\n",
    "        group_uuid = merged_document.metadata.get(\"parent_file_uuid\", uuid4())\n",
    "        document_uuid = merged_document.metadata.get(\"uuid\", uuid4())\n",
    "\n",
    "        # Clear old documents, add new one\n",
    "        document_state = state[\"documents\"].copy()\n",
    "        \n",
    "        for group in document_state:\n",
    "            for document in document_state[group]:\n",
    "                document_state[group][document] = None\n",
    "        \n",
    "        document_state[group_uuid][document_uuid] = merged_document\n",
    "        \n",
    "        return {\n",
    "            \"documents\": document_state\n",
    "        }\n",
    "\n",
    "    return _merge\n",
    "\n",
    "merge_state = State(\n",
    "    request=ChainInput(\n",
    "        question=\"What animals are named in these documents?\",\n",
    "        file_uuids=[\"71b76e2a-9c2f-4340-ba94-cc09c7de74ff\"],\n",
    "        user_uuid=\"a16b2762-fc18-4595-bafa-3d70f1e85087\",\n",
    "        chat_history=[],\n",
    "    ).dict(),\n",
    "    text=None,\n",
    "    documents={\n",
    "        UUID(\"00000000-0000-0000-0000-000000000001\"): {\n",
    "            UUID(\"10000000-0000-0000-0000-000000000000\"): Document(\n",
    "                page_content=\"A dog is a type of mammal.\",\n",
    "                metadata={\n",
    "                    \"uuid\": UUID(\"10000000-0000-0000-0000-000000000000\"),\n",
    "                    \"parent_file_uuid\": UUID(\"00000000-0000-0000-0000-000000000001\"),\n",
    "                    \"token_count\": 6,\n",
    "                }\n",
    "            ),\n",
    "            UUID(\"20000000-0000-0000-0000-000000000000\"): Document(\n",
    "                page_content=\"A cat is a type of mammal.\",\n",
    "                metadata={\n",
    "                    \"uuid\": UUID(\"20000000-0000-0000-0000-000000000000\"),\n",
    "                    \"parent_file_uuid\": UUID(\"00000000-0000-0000-0000-000000000001\"),\n",
    "                    \"token_count\": 6,\n",
    "                }\n",
    "            )\n",
    "        },\n",
    "        UUID(\"00000000-0000-0000-0000-000000000002\"): {\n",
    "            UUID(\"30000000-0000-0000-0000-000000000000\"): Document(\n",
    "                page_content=\"A swift is a type of bird.\",\n",
    "                metadata={\n",
    "                    \"uuid\": UUID(\"30000000-0000-0000-0000-000000000000\"),\n",
    "                    \"parent_file_uuid\": UUID(\"00000000-0000-0000-0000-000000000002\"),\n",
    "                    \"token_count\": 6,\n",
    "                }\n",
    "            ),\n",
    "            UUID(\"40000000-0000-0000-0000-000000000000\"): Document(\n",
    "                page_content=\"A shrike is a type of bird.\",\n",
    "                metadata={\n",
    "                    \"uuid\": UUID(\"40000000-0000-0000-0000-000000000000\"),\n",
    "                    \"parent_file_uuid\": UUID(\"00000000-0000-0000-0000-000000000002\"),\n",
    "                    \"token_count\": 6,\n",
    "                }\n",
    "            )\n",
    "        }\n",
    "    },\n",
    "    route=None\n",
    ")\n",
    "\n",
    "merge_node = make_merge_pattern(\n",
    "    system_prompt=\"Summarise these documents.\", \n",
    "    question_prompt=\"Question: {question}. \\n\\n Documents: \\n\\n {documents} \\n\\n Answer:\",\n",
    "    llm=llm\n",
    ")\n",
    "\n",
    "merge_node(merge_state, AI_CONFIG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group:00000000-0000-0000-0000-000000000001\n",
      "Document:10000000-0000-0000-0000-000000000000\n",
      "Document:20000000-0000-0000-0000-000000000000\n",
      "---\n",
      "Group:00000000-0000-0000-0000-000000000002\n",
      "Document:30000000-0000-0000-0000-000000000000\n",
      "Document:40000000-0000-0000-0000-000000000000\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "def make_retrieve_pattern(\n",
    "    retriever: BaseRetriever\n",
    ") -> Callable[[State, AISettings], dict[str, Any]]:\n",
    "    \"\"\"Returns a function that uses state[\"request\"] and state[\"text\"] to set state[\"documents\"].\"\"\"\n",
    "    def _retrieve(state: State, config: AISettings) -> dict[str, Any]:\n",
    "        document_states: list[DocumentState] = []\n",
    "        request = state[\"request\"]\n",
    "        request[\"question\"] = state[\"text\"]\n",
    "\n",
    "        for document in retriever.invoke(request):\n",
    "            group_uuid = document.metadata.get(\"parent_file_uuid\", uuid4())\n",
    "            chunk_uuid = document.metadata.get(\"uuid\", uuid4())\n",
    "            document_states.append({ group_uuid: { chunk_uuid: document } })\n",
    "    \n",
    "        return {\n",
    "            \"documents\": reduce(lambda l, r: document_reducer(l, r), document_states)\n",
    "        }\n",
    "\n",
    "    return _retrieve\n",
    "\n",
    "\n",
    "class FakeRetriever(BaseRetriever):\n",
    "    docs: list[Document]\n",
    "\n",
    "    def _get_relevant_documents(self, query: str) -> list[Document]:\n",
    "        return self.docs\n",
    "\n",
    "    async def _aget_relevant_documents(self, query: str) -> list[Document]:\n",
    "        return self.docs\n",
    "\n",
    "\n",
    "fake_retriever = FakeRetriever(\n",
    "    docs=[\n",
    "        Document(\n",
    "            page_content=\"A dog is a type of mammal.\",\n",
    "            metadata={\n",
    "                \"uuid\": UUID(\"10000000-0000-0000-0000-000000000000\"),\n",
    "                \"parent_file_uuid\": UUID(\"00000000-0000-0000-0000-000000000001\"),\n",
    "                \"token_count\": 6,\n",
    "            }\n",
    "        ),\n",
    "        Document(\n",
    "            page_content=\"A cat is a type of mammal.\",\n",
    "            metadata={\n",
    "                \"uuid\": UUID(\"20000000-0000-0000-0000-000000000000\"),\n",
    "                \"parent_file_uuid\": UUID(\"00000000-0000-0000-0000-000000000001\"),\n",
    "                \"token_count\": 6,\n",
    "            }\n",
    "        ),\n",
    "        Document(\n",
    "            page_content=\"A swift is a type of bird.\",\n",
    "            metadata={\n",
    "                \"uuid\": UUID(\"30000000-0000-0000-0000-000000000000\"),\n",
    "                \"parent_file_uuid\": UUID(\"00000000-0000-0000-0000-000000000002\"),\n",
    "                \"token_count\": 6,\n",
    "            }\n",
    "        ),\n",
    "        Document(\n",
    "            page_content=\"A shrike is a type of bird.\",\n",
    "            metadata={\n",
    "                \"uuid\": UUID(\"40000000-0000-0000-0000-000000000000\"),\n",
    "                \"parent_file_uuid\": UUID(\"00000000-0000-0000-0000-000000000002\"),\n",
    "                \"token_count\": 6,\n",
    "            }\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "retrieve_state = State(\n",
    "    request=ChainInput(\n",
    "        question=\"What are some animals?\",\n",
    "        file_uuids=[\"71b76e2a-9c2f-4340-ba94-cc09c7de74ff\"],\n",
    "        user_uuid=\"a16b2762-fc18-4595-bafa-3d70f1e85087\",\n",
    "        chat_history=[],\n",
    "    ).dict(),\n",
    "    text=None,\n",
    "    documents=None,\n",
    "    route=None\n",
    ")\n",
    "\n",
    "retrieve_node = make_retrieve_pattern(retriever=fake_retriever)\n",
    "\n",
    "document_state = retrieve_node(retrieve_state, AI_CONFIG)\n",
    "\n",
    "for group in document_state[\"documents\"]:\n",
    "    print(f\"Group:{group}\")\n",
    "    for document in document_state[\"documents\"][group]:\n",
    "        print(f\"Document:{document}\")\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subgraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'request': {'question': 'What are some animals?',\n",
       "  'file_uuids': [UUID('71b76e2a-9c2f-4340-ba94-cc09c7de74ff')],\n",
       "  'user_uuid': UUID('a16b2762-fc18-4595-bafa-3d70f1e85087'),\n",
       "  'chat_history': [{'role': 'user', 'text': 'Who are ye?'},\n",
       "   {'role': 'ai', 'text': \"Avast ye I'm Blackbeard!\"}]},\n",
       " 'text': \"Arrr, there be many creatures on land and sea! Ye've got the mighty whale, the cunning fox, the fierce tiger, and the swift eagle, just to name a few. What be ye interested in, matey?\",\n",
       " 'documents': None,\n",
       " 'route': None}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "chat = StateGraph(State)\n",
    "\n",
    "chat.add_node(\n",
    "    \"chat\",\n",
    "    make_chat_pattern(\n",
    "        system_prompt=\"You're a pirate.\", \n",
    "        question_prompt=\"{question}\\n\\n Response: \",\n",
    "        llm=llm\n",
    "    )\n",
    ")\n",
    "\n",
    "chat.add_edge(START, \"chat\")\n",
    "chat.add_edge(\"chat\", END)\n",
    "\n",
    "chat_compiled = chat.compile()\n",
    "\n",
    "chat_state = State(\n",
    "    request=ChainInput(\n",
    "        question=\"What are some animals?\",\n",
    "        file_uuids=[\"71b76e2a-9c2f-4340-ba94-cc09c7de74ff\"],\n",
    "        user_uuid=\"a16b2762-fc18-4595-bafa-3d70f1e85087\",\n",
    "        chat_history=[\n",
    "            {\"role\": \"user\", \"text\": \"Who are ye?\"},\n",
    "            {\"role\": \"ai\", \"text\": \"Avast ye I'm Blackbeard!\"},\n",
    "        ],\n",
    "    ).dict(),\n",
    "    text=None,\n",
    "    documents=None,\n",
    "    route=None\n",
    ")\n",
    "\n",
    "chat_compiled.invoke(input=chat_state, config=AI_CONFIG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'request': {'question': 'What are some examples of different types of animals?',\n",
       "  'file_uuids': [UUID('71b76e2a-9c2f-4340-ba94-cc09c7de74ff')],\n",
       "  'user_uuid': UUID('a16b2762-fc18-4595-bafa-3d70f1e85087'),\n",
       "  'chat_history': []},\n",
       " 'text': 'Examples of different types of animals include:\\n\\n- Dogs and cats, which are types of mammals.\\n- Swifts and shrikes, which are types of birds.',\n",
       " 'documents': {UUID('00000000-0000-0000-0000-000000000001'): {UUID('10000000-0000-0000-0000-000000000000'): Document(metadata={'uuid': UUID('10000000-0000-0000-0000-000000000000'), 'parent_file_uuid': UUID('00000000-0000-0000-0000-000000000001'), 'token_count': 6}, page_content='A dog is a type of mammal.'),\n",
       "   UUID('20000000-0000-0000-0000-000000000000'): Document(metadata={'uuid': UUID('20000000-0000-0000-0000-000000000000'), 'parent_file_uuid': UUID('00000000-0000-0000-0000-000000000001'), 'token_count': 6}, page_content='A cat is a type of mammal.')},\n",
       "  UUID('00000000-0000-0000-0000-000000000002'): {UUID('30000000-0000-0000-0000-000000000000'): Document(metadata={'uuid': UUID('30000000-0000-0000-0000-000000000000'), 'parent_file_uuid': UUID('00000000-0000-0000-0000-000000000002'), 'token_count': 6}, page_content='A swift is a type of bird.'),\n",
       "   UUID('40000000-0000-0000-0000-000000000000'): Document(metadata={'uuid': UUID('40000000-0000-0000-0000-000000000000'), 'parent_file_uuid': UUID('00000000-0000-0000-0000-000000000002'), 'token_count': 6}, page_content='A shrike is a type of bird.')}},\n",
       " 'route': None}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "rag = StateGraph(State)\n",
    "\n",
    "rag.add_node(\n",
    "    \"rag_chat\",\n",
    "    make_chat_pattern(\n",
    "        system_prompt=\"Write the following chat as a single question.\", \n",
    "        question_prompt=\"{question}\\n\\n Single question: \",\n",
    "        llm=llm\n",
    "    )\n",
    ")\n",
    "rag.add_node(\n",
    "    \"rag_retrieve\", \n",
    "    make_retrieve_pattern(retriever=fake_retriever)\n",
    ")\n",
    "rag.add_node(\n",
    "    \"rag_stuff\",\n",
    "    make_stuff_pattern(\n",
    "        system_prompt=\"Summarise these documents.\", \n",
    "        question_prompt=\"Question: {question}. \\n\\n Documents: \\n\\n {documents} \\n\\n Answer:\",\n",
    "        llm=llm\n",
    "    )\n",
    ")\n",
    "\n",
    "rag.add_edge(START, \"rag_chat\")\n",
    "rag.add_edge(\"rag_chat\", \"rag_retrieve\")\n",
    "rag.add_edge(\"rag_retrieve\", \"rag_stuff\")\n",
    "rag.add_edge(\"rag_stuff\", END)\n",
    "\n",
    "rag_compiled = rag.compile()\n",
    "\n",
    "rag_state = State(\n",
    "    request=ChainInput(\n",
    "        question=\"What are some animals?\",\n",
    "        file_uuids=[\"71b76e2a-9c2f-4340-ba94-cc09c7de74ff\"],\n",
    "        user_uuid=\"a16b2762-fc18-4595-bafa-3d70f1e85087\",\n",
    "        chat_history=[],\n",
    "    ).dict(),\n",
    "    text=None,\n",
    "    documents=None,\n",
    "    route=None\n",
    ")\n",
    "\n",
    "rag_compiled.invoke(input=rag_state, config=AI_CONFIG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Node `cwd_shrink` is not reachable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[58], line 65\u001b[0m\n\u001b[1;32m     62\u001b[0m cwd\u001b[38;5;241m.\u001b[39madd_edge(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcwd_group_merge\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcwd_stuff\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     63\u001b[0m cwd\u001b[38;5;241m.\u001b[39madd_edge(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcwd_stuff\u001b[39m\u001b[38;5;124m\"\u001b[39m, END)\n\u001b[0;32m---> 65\u001b[0m cwd_compiled \u001b[38;5;241m=\u001b[39m \u001b[43mcwd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m cwd_state \u001b[38;5;241m=\u001b[39m State(\n\u001b[1;32m     68\u001b[0m     request\u001b[38;5;241m=\u001b[39mChainInput(\n\u001b[1;32m     69\u001b[0m         question\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat are some animals?\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     76\u001b[0m     route\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     77\u001b[0m )\n\u001b[1;32m     79\u001b[0m cwd_compiled\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mcwd_state, config\u001b[38;5;241m=\u001b[39mAI_CONFIG)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/redbox-VIdz9l6D-py3.12/lib/python3.12/site-packages/langgraph/graph/state.py:396\u001b[0m, in \u001b[0;36mStateGraph.compile\u001b[0;34m(self, checkpointer, interrupt_before, interrupt_after, debug)\u001b[0m\n\u001b[1;32m    393\u001b[0m interrupt_after \u001b[38;5;241m=\u001b[39m interrupt_after \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[1;32m    395\u001b[0m \u001b[38;5;66;03m# validate the graph\u001b[39;00m\n\u001b[0;32m--> 396\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterrupt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m*\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minterrupt_after\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m*\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    400\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;66;03m# prepare output channels\u001b[39;00m\n\u001b[1;32m    405\u001b[0m output_channels \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    406\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__root__\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    407\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mschemas[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput]) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    413\u001b[0m     ]\n\u001b[1;32m    414\u001b[0m )\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/redbox-VIdz9l6D-py3.12/lib/python3.12/site-packages/langgraph/graph/graph.py:347\u001b[0m, in \u001b[0;36mGraph.validate\u001b[0;34m(self, interrupt)\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnodes:\n\u001b[1;32m    346\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m node \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m all_targets:\n\u001b[0;32m--> 347\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNode `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` is not reachable\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m target \u001b[38;5;129;01min\u001b[39;00m all_targets:\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m target \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnodes \u001b[38;5;129;01mand\u001b[39;00m target \u001b[38;5;241m!=\u001b[39m END:\n",
      "\u001b[0;31mValueError\u001b[0m: Node `cwd_shrink` is not reachable"
     ]
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "cwd = StateGraph(State)\n",
    "\n",
    "cwd.add_node(\n",
    "    \"cwd_passthrough\",\n",
    "    make_passthrough_pattern()\n",
    ")\n",
    "cwd.add_node(\n",
    "    \"cwd_retrieve\", \n",
    "    make_retrieve_pattern(retriever=fake_retriever)\n",
    ")\n",
    "cwd.add_node(\n",
    "    \"cwd_stuff\",\n",
    "    make_stuff_pattern(\n",
    "        system_prompt=\"Summarise these documents.\", \n",
    "        question_prompt=\"Question: {question}. \\n\\n Documents: \\n\\n {documents} \\n\\n Answer:\",\n",
    "        llm=llm\n",
    "    )\n",
    ")\n",
    "cwd.add_node(\n",
    "    \"cwd_chunk_send_to_shrink\",\n",
    "    make_document_chunk_send(\"cwd_shrink\")\n",
    ")\n",
    "cwd.add_node(\n",
    "    \"cwd_shrink\",\n",
    "    make_merge_pattern(\n",
    "        system_prompt=\"Summarise these documents.\", \n",
    "        question_prompt=\"Question: {question}. \\n\\n Documents: \\n\\n {documents} \\n\\n Answer:\",\n",
    "        llm=llm\n",
    "    )\n",
    ")\n",
    "cwd.add_node(\n",
    "    \"cwd_canned_error\",\n",
    "    make_chat_canned_pattern(canned=\"These documents are too large to work with.\")\n",
    ")\n",
    "cwd.add_node(\n",
    "    \"cwd_group_send_to_merge\",\n",
    "    make_document_group_send(\"cwd_group_merge\")\n",
    ")\n",
    "cwd.add_node(\n",
    "    \"cwd_group_merge\",\n",
    "    make_merge_pattern(\n",
    "        system_prompt=\"Summarise these documents.\", \n",
    "        question_prompt=\"Question: {question}. \\n\\n Documents: \\n\\n {documents} \\n\\n Answer:\",\n",
    "        llm=llm\n",
    "    )\n",
    ")\n",
    "\n",
    "cwd.add_edge(START, \"cwd_passthrough\")\n",
    "cwd.add_edge(\"cwd_passthrough\", \"cwd_retrieve\")\n",
    "cwd.add_conditional_edges(\n",
    "    \"cwd_retrieve\", \n",
    "    conditional_doceuments_bigger_than_context, \n",
    "    {True: \"cwd_chunk_send_to_shrink\", False: \"cwd_stuff\"}\n",
    ")\n",
    "cwd.add_conditional_edges(\n",
    "    \"cwd_shrink\",\n",
    "    conditional_multiple_docs_in_group,\n",
    "    {True: \"cwd_group_send_to_merge\", False: \"cwd_stuff\"}\n",
    ")\n",
    "cwd.add_edge(\"cwd_group_merge\", \"cwd_stuff\")\n",
    "cwd.add_edge(\"cwd_stuff\", END)\n",
    "\n",
    "cwd_compiled = cwd.compile()\n",
    "\n",
    "cwd_state = State(\n",
    "    request=ChainInput(\n",
    "        question=\"What are some animals?\",\n",
    "        file_uuids=[\"71b76e2a-9c2f-4340-ba94-cc09c7de74ff\"],\n",
    "        user_uuid=\"a16b2762-fc18-4595-bafa-3d70f1e85087\",\n",
    "        chat_history=[],\n",
    "    ).dict(),\n",
    "    text=None,\n",
    "    documents=None,\n",
    "    route=None\n",
    ")\n",
    "\n",
    "cwd_compiled.invoke(input=cwd_state, config=AI_CONFIG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
